# Internship Project: Debiasing Language Generation through  Generative Adversarial Network

## Abstract
High-profile cases of machine bias causing serious social harm, bias mitigation for language generation remains a largely unexplored space. Language models (LMs) are capable of generating language that reflects biases and harmful stereotypes. We are developing a framework designed to mitigate biased output from language models. Most of these previous growing literature base on evaluation of bias and stereotyping in natural language text, rather than debiasing the output from language models. The previous methods mitigate bias by masking sensitive words which sacrifice the perplexity of the langauge model. We propose a framework that jointly generates meaningful languages and mitigate bias from the generated sentence through generated adversarial network training (GAN) method.  Moreover, our framework does not rely on the classifier model, which eases its adaptation to different systems. Besides, we created a new merged fair sensitive word list including holistic dataset, bold dataset, and gender bias dataset, and an augmented evaluation prompts from gender, race, and age kingdoms including 17 classes. Experiments on 3 kingdoms gender, race, and age prompts shows that our method achieves significantly better or competitive results compared to baseline models.

## Code Structure
```
FairLM
│   README.md
│
└───Code
|   |   run_lm_owtc                 # Language model training using OpenWebTextCorpus dataset (retrain GPT2-small)
│   │   run_lm_fair_mask.sh         # Language model training with/without mask tokens 
│   │   run_lm_fair_mask_eval.sh    # Language model training with/without mask tokens load from checkpoint
│   │   run_classifier.sh           # Classifier training with option GPT2 or RoBERTa
|   |   run_main_adv.sh             # GAN style traninng with option GPT2-GPT2 (init), GPT2-GPT2 (pretrain), GPT2-RoBERTa (init), and GPT2-RoBERTa (pretrain)
|   |   run_eval.sh                 # Evaluation of models based on GAN style generator over gender, race, and age
|   |   Classifier.py               # Classifier Model (GPT2, RoBERTa)
|   |   lm_finetuning.py            # Language Model (GPT2)
|   |   main_adv.py                 # Train FairLM Main Model
|   |   FairEvaluation.py           # Evaluation Model
|   |   plot_train.ipynb            # Plot the loss of the FairLM and analysis the best hyperparameter combination such as the DIS-GEN update ratio, alpha, sample size, and final result including perpleixty and fairness result.
|   |   debiaswe                    # Debiaswe embedding and API from Github (https://github.com/tolga-b/debiaswe)
|   └───utils                       # Module of utils functions
|   |   |    data_processing.py     # Transform raw data into model input
|   |   |    modules.py             # Modules of functions for models
|   |   |    train_and_val.py       # Train model and validation module for GPT2 and RoBERTa
|   |   |    util.py                # Util functions
│   
└───Preprocess                      # process the knowledge source
│   │   data_preprocessing.ipynb    # LM training data preprocessing including sensitive word list
│   │   prompt_preprocessing.ipynb  # Evaluation prompt preprocessing
│   │   README.md                   
│      
└───data                            # fairness sensitive dataset and evaluation prompt
│   │   mask_token/                 # sensitive words list in age, gender, race, and temp data generated by GAN model, sensitive data are from (Holistic, https://github.com/facebookresearch/ResponsibleNLP, BOLD, https://github.com/amazon-research/bold/tree/main/prompts, GenderBias, https://github.com/navid-rekabsaz/GenderBias_IR/tree/master/resources)
│   │   prompt/                     # Prompts for language generation and code generation 
│   │   ResponsibleNLP/             # Holistic dataset from Github (https://github.com/facebookresearch/ResponsibleNLP)
│   │   wikitest-103-raw/           # Wikitest-103 test dataset for evaluation of language model perplexity
│   │   README.md
│ 
└───output      
│   │   aux/                         # Discriminator Auxiliray model (GPT2-Aux and RoBERTa-Aux)
│   │   main/                        # Generator Main Model
|   |      └───   gpt2-base/         # Save different training model parameters's checkpoint
|   |      └───   gpt2-main-gpt2-aux/# Save GTP2-GPT2 perpleixty result
|   |      └───   gpt2-main-roberta-base-aux/ # Save GTP2-Roberta perpleixty result
|   |   pretrained/                  # Pretrained Model checkpiont
|   |      └───   cls/               # classifier of pretrained GPT2 and RoBERTa
|   |      └───   lm/block-256
|   |              └─── fair_mask    # Baseline Language model with masked probability 1, 0.5, 0.15
|   |              └─── regular      # Baseline Language model trained with OWTC dataset
│   │   README.md
│    
└───log      
│    │   adv/                        # Adversarial Model training log
│    │   cls/                        # pretrained classifier model (GPT2, RoBERTa)
│    │   eval/                       # Evaluation of the GAN trained language model
│    │   lm/                         # Training of baseline masked LM and owtc LM
│    │   README.md
│ 
└───loss_plot
│    │ README.md
└───fig
│    │ README.md
```

## Data and Results

Data, loss, fig, and output (models) are stored in S3:yuantol-intern-us-west-2.

## Install Environment

```bash
conda env create -f environment.yml
```


## More Details

See FairLM/README.md for more details.
